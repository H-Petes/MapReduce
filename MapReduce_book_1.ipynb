{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MapReduce_book 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/H-Petes/MapReduce/blob/master/MapReduce_book_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9yBIAPYUr7w",
        "colab_type": "text"
      },
      "source": [
        "**MapReduce**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEWMH76GU3hr",
        "colab_type": "text"
      },
      "source": [
        "## Objective\n",
        "\n",
        "In this practice, we try to\n",
        "\n",
        "+ Understand and become familiar with MapReduce.\n",
        "+ Apply MapReduce to solve different problems\n",
        "+ Learn how to frame a problem in MapReduce\n",
        "+ Use Elastic MapReduce to work with large databases.\n",
        "\n",
        "You should spend time to think and understand MapReduce framework, as well as playing with the code to see what happens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quICSdLyZvS8",
        "colab_type": "text"
      },
      "source": [
        "## mrjob\n",
        "\n",
        "[mrjob](https://github.com/Yelp/mrjob) is a Python library that allows us to write MapReduce job in Python and run it on different platforms. \n",
        "\n",
        "For example, we can run the job:\n",
        "+ On a local machine (to test)\n",
        "+ On a Hadoop cluster\n",
        "+ In the cloud using Amazon Elastic MapReduce (EMR)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55xUE8I_cSTA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "348be846-c19d-46de-dba5-69f150fb3794"
      },
      "source": [
        "# Install mrjob package\n",
        "!pip install mrjob"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mrjob in /usr/local/lib/python3.6/dist-packages (0.7.3)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from mrjob) (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA0dZAKvh03i",
        "colab_type": "text"
      },
      "source": [
        "## First example \n",
        "Counting the number of words in a document:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lxv5-aPAh-3O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "407ae497-5994-4702-cf26-29e7914de42d"
      },
      "source": [
        "%%writefile eg1.py\n",
        "from mrjob.job import MRJob\n",
        "\n",
        "class WordCount1(MRJob):\n",
        "    def mapper(self, _, line):\n",
        "        yield \"words\", len(line.split())\n",
        "\n",
        "    def reducer(self, key, values):\n",
        "        yield key, sum(values)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    WordCount1.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting eg1.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi11N-4oisC3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "b3cf491c-edff-48d9-e013-902fbeb4de04"
      },
      "source": [
        "!python eg1.py /content/sample_data/README.md"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory /tmp/eg1.root.20200804.084038.681921\n",
            "Running step 1 of 1...\n",
            "job output is in /tmp/eg1.root.20200804.084038.681921/output\n",
            "Streaming final output from /tmp/eg1.root.20200804.084038.681921/output...\n",
            "\"words\"\t80\n",
            "Removing temp directory /tmp/eg1.root.20200804.084038.681921...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GSDVDSGi5Vt",
        "colab_type": "text"
      },
      "source": [
        "**What's happening here?**\n",
        "\n",
        "**MapReduce job**\n",
        "\n",
        "We import the class `MRJob` in `mrjob.job`. Then, we define our MapReduce class with `MRJob` as the parent class. \n",
        "\n",
        "In our new class `WordCount1`, we define 2 methods `mapper` and `reducer`, which are the map task and the reduce task. In this example where we have 1 map task and 1 reduce task, their names must be exactly `mapper` and `reducer`.\n",
        "\n",
        "`mapper` receive a pair of key and value as input. For the `mapper` in the example, the key is ignored, the value is a line of the document. For each line, the `mapper` outputs a pair of key:value. As we can see, here we define the key as `\"words\"`, and it's the unique key. The value is the number of words in the line. `line.split()` gives us a list of 'words' in the line, so `len(line.split())` gives us the number of words in a line.\n",
        "\n",
        "The `reducer` receives as input a key and an iterator of values (all tha values that share the corresponding key). As we've mentionned our unique key is \"words\", so the keys are numbers of words each line. As we want to count the number of words in the document we just output the key `\"words\"` (we choose again), and the sum of the above numbers.\n",
        "\n",
        "Because `mrjob` wants an iterator as `output` of a `mapper` or reducer, we must use `yeild`, and not `return`.\n",
        "\n",
        "**Run the code**\n",
        "\n",
        "We write our code into a file called `mr1.py`. We also add\n",
        "```\n",
        "if __name__ == '__main__':\n",
        "    WordCount1.run()\n",
        "```\n",
        "at the end so that we can run the code from the command-line. \n",
        "\n",
        "To run the code we execute:\n",
        "```\n",
        "!python mr1.py /content/sample_data/README.md\n",
        "```\n",
        "which consists of the code file `eg1.py` and the input of the MapReduce job `/content/sample_data/README.md`.\n",
        "\n",
        "**Result**\n",
        "\n",
        "We obtain some notifications and the result of the job `\"words\"\t80`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ezr780ZRXkqv",
        "colab_type": "text"
      },
      "source": [
        "## Ex1\n",
        "\n",
        "1. Based on the code above, write a file called `mr1.py` to count the number of characters in the above document. Run the job.\n",
        "\n",
        "1. `mapper` may `yeild` as many key-value pairs as we want. In other words, we may have many `yeild` in the mapper codes. Let's say you use the key `\"characters\"` for the previous task. Modify your code to count the number of lines, by adding another `yield` to the mapper, with key `\"lines\"` and an appropriate value. Run the job."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aly0x8Nz3-jw",
        "colab_type": "text"
      },
      "source": [
        "## Running the job diferently\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7uoDYA75cLf",
        "colab_type": "text"
      },
      "source": [
        "Pass input via stdin (note: mrjob will just dump it to a file first): "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0QR2J5GqS2J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "145f4fc5-477e-4c57-f736-d02fc2b2c918"
      },
      "source": [
        "%%writefile mr1.py\n",
        "from mrjob.job import MRJob\n",
        "\n",
        "class WordCount1(MRJob):\n",
        "    def mapper(self, _, line):\n",
        "        yield \"characters\", len(line)\n",
        "        yield \"lines\", 1\n",
        "\n",
        "    def reducer(self, key, values):\n",
        "        yield key, sum(values)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    WordCount1.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting mr1.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03a1FeMe5xHO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "7def040c-8b3f-4d71-9e58-41a5983f1405"
      },
      "source": [
        "!python mr1.py < /content/sample_data/README.md"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory /tmp/mr1.root.20200804.085231.505584\n",
            "Running step 1 of 1...\n",
            "reading from STDIN\n",
            "job output is in /tmp/mr1.root.20200804.085231.505584/output\n",
            "Streaming final output from /tmp/mr1.root.20200804.085231.505584/output...\n",
            "\"lines\"\t19\n",
            "\"characters\"\t911\n",
            "Removing temp directory /tmp/mr1.root.20200804.085231.505584...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHGDXhvD5cD_",
        "colab_type": "text"
      },
      "source": [
        "Multiple input files:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ik8Je5-Y4BHb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e648cece-c95c-44c2-be8d-2f48931560f2"
      },
      "source": [
        "%%writefile mytext1.txt\n",
        "Hello world"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing mytext1.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq0oDiHt4nBI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3bd1fcf-6abe-4d97-f107-056eff3ffe18"
      },
      "source": [
        "%%writefile mytext2.txt\n",
        "Good bye"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing mytext2.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a2qlugYx6-U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "c3730d50-1c0d-4303-af28-648dc8bbfad4"
      },
      "source": [
        "# 3 input files\n",
        "!python mr1.py /content/sample_data/README.md mytext1.txt - < mytext2.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory /tmp/mr1.root.20200804.085450.851622\n",
            "Running step 1 of 1...\n",
            "reading from STDIN\n",
            "job output is in /tmp/mr1.root.20200804.085450.851622/output\n",
            "Streaming final output from /tmp/mr1.root.20200804.085450.851622/output...\n",
            "\"lines\"\t21\n",
            "\"characters\"\t930\n",
            "Removing temp directory /tmp/mr1.root.20200804.085450.851622...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKyFRNjj7eDm",
        "colab_type": "text"
      },
      "source": [
        "Write the result to a file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueshPd3P407h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "a1a05b42-4be4-4153-fcb8-4edab821252e"
      },
      "source": [
        "# write the result to result1.txt\n",
        "!python mr1.py /content/sample_data/README.md mytext1.txt - < mytext2.txt > result1.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory /tmp/mr1.root.20200804.085524.328427\n",
            "Running step 1 of 1...\n",
            "reading from STDIN\n",
            "job output is in /tmp/mr1.root.20200804.085524.328427/output\n",
            "Streaming final output from /tmp/mr1.root.20200804.085524.328427/output...\n",
            "Removing temp directory /tmp/mr1.root.20200804.085524.328427...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-m1hfZBmJu0A",
        "colab_type": "text"
      },
      "source": [
        "## Ex2\n",
        "\n",
        "We've counted the number of words in a document. Now we want to know how many times each word occurs.\n",
        "\n",
        "To do so we change the mapper so that, for each line, we will yield many pairs of key-value. Each word (not necessarily distinct) is a key, and the corresponding value is 1 (which means the word is counted once).\n",
        "\n",
        "In the reducer for each input key (a distinct word), we take the sum of all values to count the number of occurences.\n",
        "\n",
        "Write a code to count know how many times each word occurs into a file called `mr2.py` and run it with the text file `/content/sample_data/README.md`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_6pOUhAscot",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ff3e2fb-99ac-46d1-df30-421e4ebfae00"
      },
      "source": [
        "%%writefile mr2.py\n",
        "from mrjob.job import MRJob\n",
        "\n",
        "class WordCount1(MRJob):\n",
        "    def mapper(self, _, line):\n",
        "        for word in line.split():\n",
        "            yield word, 1\n",
        "\n",
        "    def reducer(self, key, values):\n",
        "        yield key, sum(values)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    WordCount1.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting mr2.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3MFLwFptm7z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "39d1df74-9411-46b9-c7bc-215a7e5caac5"
      },
      "source": [
        "!python mr2.py < /content/sample_data/README.md"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory /tmp/mr2.root.20200804.090502.066463\n",
            "Running step 1 of 1...\n",
            "reading from STDIN\n",
            "job output is in /tmp/mr2.root.20200804.090502.066463/output\n",
            "Streaming final output from /tmp/mr2.root.20200804.090502.066463/output...\n",
            "\"more\"\t1\n",
            "\"of\"\t2\n",
            "\"originally\"\t1\n",
            "\"our\"\t1\n",
            "\"prepared\"\t1\n",
            "\"quartet](https://en.wikipedia.org/wiki/Anscombe%27s_quartet);\"\t1\n",
            "\"sample\"\t2\n",
            "\"small\"\t1\n",
            "\"started.\"\t1\n",
            "\"the\"\t3\n",
            "\"to\"\t1\n",
            "\"was\"\t2\n",
            "\"which\"\t1\n",
            "\"you\"\t1\n",
            "\"http://yann.lecun.com/exdb/mnist/\"\t1\n",
            "\"https://developers.google.com/machine-learning/crash-course/california-housing-data-description\"\t1\n",
            "\"in\"\t2\n",
            "\"includes\"\t1\n",
            "\"information\"\t1\n",
            "\"is\"\t4\n",
            "\"it\"\t1\n",
            "\"library](https://github.com/altair-viz/vega_datasets/blob/4f67bdaad10f45e3549984e17e1b3088c731503d/vega_datasets/_data/anscombe.json).\"\t1\n",
            "\"`california_housing_data*.csv`\"\t1\n",
            "\"`mnist_*.csv`\"\t1\n",
            "\"a\"\t3\n",
            "\"and\"\t1\n",
            "\"at:\"\t2\n",
            "\"available\"\t1\n",
            "\"by\"\t1\n",
            "\"contains\"\t1\n",
            "\"copy\"\t2\n",
            "\"data\"\t1\n",
            "\"database](https://en.wikipedia.org/wiki/MNIST_database),\"\t1\n",
            "\"datasets\"\t1\n",
            "\"described\"\t2\n",
            "\"directory\"\t1\n",
            "\"few\"\t1\n",
            "\"from\"\t1\n",
            "\"get\"\t1\n",
            "\"housing\"\t1\n",
            "\"'Graphs\"\t1\n",
            "\"(1):\"\t1\n",
            "\"(1973).\"\t1\n",
            "\"*\"\t3\n",
            "\"17-21.\"\t1\n",
            "\"1990\"\t1\n",
            "\"2682899.\"\t1\n",
            "\"27\"\t1\n",
            "\"American\"\t1\n",
            "\"Analysis'.\"\t1\n",
            "\"Anscombe,\"\t1\n",
            "\"California\"\t1\n",
            "\"Census;\"\t1\n",
            "\"F.\"\t1\n",
            "\"J.\"\t1\n",
            "\"JSTOR\"\t1\n",
            "\"Statistical\"\t1\n",
            "\"Statistician.\"\t1\n",
            "\"This\"\t1\n",
            "\"US\"\t1\n",
            "\"[Anscombe's\"\t1\n",
            "\"[MNIST\"\t1\n",
            "\"[vega_datasets\"\t1\n",
            "\"`anscombe.json`\"\t1\n",
            "Removing temp directory /tmp/mr2.root.20200804.090502.066463...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xDxGoiXNnPW",
        "colab_type": "text"
      },
      "source": [
        "## Ex3\n",
        "\n",
        "In the previous task if you haven't used some regular expression yet, then you can see in the result that the code consider punctuations as parts of words.\n",
        "\n",
        "+ Use this to define a regular expression pattern:\n",
        "\n",
        "```\n",
        "import re\n",
        "\n",
        "WORD_RE = re.compile(r\"[\\w']+\")\n",
        "```\n",
        "\n",
        "+ In you mapper code, use this to have a list of words (all non-overlapping matches of pattern):\n",
        "\n",
        "```\n",
        "WORD_RE.findall(line)\n",
        "```\n",
        "\n",
        "+ Also use the method `.lower()` of a string to turn a word into lower case in the maper.\n",
        "\n",
        "\n",
        "write your file as mr3.py and run it with the text file `/content/sample_data/README.md`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zicny_FfMip-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e72858ed-508b-4add-de42-58382388f5ff"
      },
      "source": [
        "%%writefile mr3.py\n",
        "from mrjob.job import MRJob\n",
        "import re\n",
        "\n",
        "WORD_RE = re.compile(r\"[\\w']+\")\n",
        "\n",
        "class WordFreq(MRJob):\n",
        "  def mapper(self, _, line):\n",
        "    for word in WORD_RE.findall(line):\n",
        "      yield word.lower(), 1\n",
        "\n",
        "  def reducer(self, key, values):\n",
        "    yield key, sum(values)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  WordFreq.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing mr3.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTRoXQ1sNZ6Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "05a2488b-36c2-4861-aa2a-c2b0f49af9f8"
      },
      "source": [
        "!python mr3.py < /content/sample_data/README.md"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory /tmp/mr3.root.20200804.112315.866695\n",
            "Running step 1 of 1...\n",
            "reading from STDIN\n",
            "job output is in /tmp/mr3.root.20200804.112315.866695/output\n",
            "Streaming final output from /tmp/mr3.root.20200804.112315.866695/output...\n",
            "\"quartet\"\t1\n",
            "\"sample\"\t2\n",
            "\"small\"\t1\n",
            "\"started\"\t1\n",
            "\"statistical\"\t1\n",
            "\"statistician\"\t1\n",
            "\"the\"\t3\n",
            "\"this\"\t1\n",
            "\"to\"\t1\n",
            "\"us\"\t1\n",
            "\"vega_datasets\"\t3\n",
            "\"viz\"\t1\n",
            "\"was\"\t2\n",
            "\"which\"\t1\n",
            "\"wiki\"\t2\n",
            "\"wikipedia\"\t2\n",
            "\"yann\"\t1\n",
            "\"you\"\t1\n",
            "\"http\"\t1\n",
            "\"https\"\t4\n",
            "\"in\"\t2\n",
            "\"includes\"\t1\n",
            "\"information\"\t1\n",
            "\"is\"\t4\n",
            "\"it\"\t1\n",
            "\"j\"\t1\n",
            "\"json\"\t2\n",
            "\"jstor\"\t1\n",
            "\"learning\"\t1\n",
            "\"lecun\"\t1\n",
            "\"library\"\t1\n",
            "\"machine\"\t1\n",
            "\"mnist\"\t2\n",
            "\"mnist_\"\t1\n",
            "\"mnist_database\"\t1\n",
            "\"more\"\t1\n",
            "\"of\"\t2\n",
            "\"org\"\t2\n",
            "\"originally\"\t1\n",
            "\"our\"\t1\n",
            "\"prepared\"\t1\n",
            "\"california_housing_data\"\t1\n",
            "\"census\"\t1\n",
            "\"com\"\t3\n",
            "\"contains\"\t1\n",
            "\"copy\"\t2\n",
            "\"course\"\t1\n",
            "\"crash\"\t1\n",
            "\"csv\"\t2\n",
            "\"data\"\t2\n",
            "\"database\"\t1\n",
            "\"datasets\"\t1\n",
            "\"described\"\t2\n",
            "\"description\"\t1\n",
            "\"developers\"\t1\n",
            "\"directory\"\t1\n",
            "\"en\"\t2\n",
            "\"exdb\"\t1\n",
            "\"f\"\t1\n",
            "\"few\"\t1\n",
            "\"from\"\t1\n",
            "\"get\"\t1\n",
            "\"github\"\t1\n",
            "\"google\"\t1\n",
            "\"housing\"\t2\n",
            "\"'graphs\"\t1\n",
            "\"1\"\t1\n",
            "\"17\"\t1\n",
            "\"1973\"\t1\n",
            "\"1990\"\t1\n",
            "\"21\"\t1\n",
            "\"2682899\"\t1\n",
            "\"27\"\t1\n",
            "\"27s_quartet\"\t1\n",
            "\"4f67bdaad10f45e3549984e17e1b3088c731503d\"\t1\n",
            "\"_data\"\t1\n",
            "\"a\"\t3\n",
            "\"altair\"\t1\n",
            "\"american\"\t1\n",
            "\"analysis'\"\t1\n",
            "\"and\"\t1\n",
            "\"anscombe\"\t4\n",
            "\"anscombe's\"\t1\n",
            "\"at\"\t2\n",
            "\"available\"\t1\n",
            "\"blob\"\t1\n",
            "\"by\"\t1\n",
            "\"california\"\t2\n",
            "Removing temp directory /tmp/mr3.root.20200804.112315.866695...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csO3GI5ZTa1i",
        "colab_type": "text"
      },
      "source": [
        "We see that the result is not perfect but better. Now that we have many pairs of word-frequency, we want to sort them by frequency. \n",
        "\n",
        "## Multiple mapper and reducer steps\n",
        "\n",
        "In MapReduce jobs, you often need to use multiple map and reduce steps. We do so by using the function `MRStep` to define a step. We then make a list steps. This list will be the output of the method `steps` of the MapReduce class.\n",
        "\n",
        "Let's see how we use multiple mapper and reducer steps to obtain sorted word frequencies:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyosugJuQvEd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32e17da5-99ed-4cbe-cfe1-0a9e51623788"
      },
      "source": [
        "%%writefile eg4.py\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.step import MRStep\n",
        "import re\n",
        "\n",
        "WORD_RE = re.compile(r\"[\\w']+\")\n",
        "\n",
        "class SortedWordFreq(MRJob):\n",
        "  def steps(self):\n",
        "    return [\n",
        "        MRStep(mapper=self.mapper1, reducer=self.reducer1),\n",
        "        MRStep(reducer=self.reducer2),\n",
        "    ]\n",
        "  def mapper1(self, _, line):\n",
        "    for word in WORD_RE.findall(line):\n",
        "      yield word.lower(), 1\n",
        "    \n",
        "  def reducer1(self, key, values):\n",
        "    yield 'OneForAll', (sum(values), key)\n",
        "    \n",
        "  def reducer2(self, _, value_key_pairs):\n",
        "    for value, key in sorted(value_key_pairs, reverse=True):\n",
        "      yield key, value\n",
        "   \n",
        "\n",
        "if __name__ == '__main__':\n",
        "  SortedWordFreq.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing eg4.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wwvx-Gz3Y1vJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "522dd734-b6ce-4bea-b229-3e75b1d189c3"
      },
      "source": [
        "!python eg4.py /content/sample_data/README.md "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory /tmp/eg4.root.20200804.112347.672958\n",
            "Running step 1 of 2...\n",
            "Running step 2 of 2...\n",
            "job output is in /tmp/eg4.root.20200804.112347.672958/output\n",
            "Streaming final output from /tmp/eg4.root.20200804.112347.672958/output...\n",
            "\"is\"\t4\n",
            "\"https\"\t4\n",
            "\"anscombe\"\t4\n",
            "\"vega_datasets\"\t3\n",
            "\"the\"\t3\n",
            "\"com\"\t3\n",
            "\"a\"\t3\n",
            "\"wikipedia\"\t2\n",
            "\"wiki\"\t2\n",
            "\"was\"\t2\n",
            "\"sample\"\t2\n",
            "\"org\"\t2\n",
            "\"of\"\t2\n",
            "\"mnist\"\t2\n",
            "\"json\"\t2\n",
            "\"in\"\t2\n",
            "\"housing\"\t2\n",
            "\"en\"\t2\n",
            "\"described\"\t2\n",
            "\"data\"\t2\n",
            "\"csv\"\t2\n",
            "\"copy\"\t2\n",
            "\"california\"\t2\n",
            "\"at\"\t2\n",
            "\"you\"\t1\n",
            "\"yann\"\t1\n",
            "\"which\"\t1\n",
            "\"viz\"\t1\n",
            "\"us\"\t1\n",
            "\"to\"\t1\n",
            "\"this\"\t1\n",
            "\"statistician\"\t1\n",
            "\"statistical\"\t1\n",
            "\"started\"\t1\n",
            "\"small\"\t1\n",
            "\"quartet\"\t1\n",
            "\"prepared\"\t1\n",
            "\"our\"\t1\n",
            "\"originally\"\t1\n",
            "\"more\"\t1\n",
            "\"mnist_database\"\t1\n",
            "\"mnist_\"\t1\n",
            "\"machine\"\t1\n",
            "\"library\"\t1\n",
            "\"lecun\"\t1\n",
            "\"learning\"\t1\n",
            "\"jstor\"\t1\n",
            "\"j\"\t1\n",
            "\"it\"\t1\n",
            "\"information\"\t1\n",
            "\"includes\"\t1\n",
            "\"http\"\t1\n",
            "\"google\"\t1\n",
            "\"github\"\t1\n",
            "\"get\"\t1\n",
            "\"from\"\t1\n",
            "\"few\"\t1\n",
            "\"f\"\t1\n",
            "\"exdb\"\t1\n",
            "\"directory\"\t1\n",
            "\"developers\"\t1\n",
            "\"description\"\t1\n",
            "\"datasets\"\t1\n",
            "\"database\"\t1\n",
            "\"crash\"\t1\n",
            "\"course\"\t1\n",
            "\"contains\"\t1\n",
            "\"census\"\t1\n",
            "\"california_housing_data\"\t1\n",
            "\"by\"\t1\n",
            "\"blob\"\t1\n",
            "\"available\"\t1\n",
            "\"anscombe's\"\t1\n",
            "\"and\"\t1\n",
            "\"analysis'\"\t1\n",
            "\"american\"\t1\n",
            "\"altair\"\t1\n",
            "\"_data\"\t1\n",
            "\"4f67bdaad10f45e3549984e17e1b3088c731503d\"\t1\n",
            "\"27s_quartet\"\t1\n",
            "\"27\"\t1\n",
            "\"2682899\"\t1\n",
            "\"21\"\t1\n",
            "\"1990\"\t1\n",
            "\"1973\"\t1\n",
            "\"17\"\t1\n",
            "\"1\"\t1\n",
            "\"'graphs\"\t1\n",
            "Removing temp directory /tmp/eg4.root.20200804.112347.672958...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fEltjSAdhjC",
        "colab_type": "text"
      },
      "source": [
        "In the above example we use a trick to make sure global sorting. We let the first `reducer` output one unique key and use the frequency-word pair as value. We don't have a second `mapper`. Because there is one unique key, there will be only one `reducer` node. It sorts the data as we want.\n",
        "\n",
        "## Ex4: \n",
        "Based on the example above, write a MapReduce job `mr4.py` to find the all characters and their frequecies in a document, and output them in sorted order. Run the code with the text file `/content/sample_data/README.md`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUs_UjWJNuXg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "936325b1-7c3a-4a88-ca22-cbe203795ce4"
      },
      "source": [
        "%%writefile mr4.py\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.step import MRStep\n",
        "\n",
        "class SortedCharFreq(MRJob):\n",
        "  def steps(self):\n",
        "    return [\n",
        "        MRStep(mapper=self.mapper1, reducer=self.reducer1),\n",
        "        MRStep(reducer=self.reducer2),\n",
        "    ]\n",
        "  def mapper1(self, _, line):\n",
        "    for character in line:\n",
        "      yield character.lower(), 1\n",
        "    \n",
        "  def reducer1(self, character, freqs):\n",
        "    yield 'OneForAll', (sum(freqs), character)\n",
        "    \n",
        "  def reducer2(self, _, value_key_pairs):\n",
        "    for freq, character in sorted(value_key_pairs, reverse=True):\n",
        "      yield character, freq\n",
        "   \n",
        "\n",
        "if __name__ == '__main__':\n",
        "  SortedCharFreq.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing mr4.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8yWNQ2cNz6g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6b862746-ccb7-4408-bf08-b5bb04ce9bbf"
      },
      "source": [
        "!python mr4.py < /content/sample_data/README.md"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory /tmp/mr4.root.20200804.112758.440403\n",
            "Running step 1 of 2...\n",
            "reading from STDIN\n",
            "Running step 2 of 2...\n",
            "job output is in /tmp/mr4.root.20200804.112758.440403/output\n",
            "Streaming final output from /tmp/mr4.root.20200804.112758.440403/output...\n",
            "\" \"\t112\n",
            "\"a\"\t77\n",
            "\"s\"\t62\n",
            "\"i\"\t57\n",
            "\"t\"\t56\n",
            "\"e\"\t53\n",
            "\"o\"\t39\n",
            "\"n\"\t39\n",
            "\"c\"\t31\n",
            "\"r\"\t30\n",
            "\"d\"\t27\n",
            "\"/\"\t27\n",
            "\".\"\t22\n",
            "\"l\"\t21\n",
            "\"m\"\t20\n",
            "\"h\"\t18\n",
            "\"b\"\t18\n",
            "\"p\"\t16\n",
            "\"g\"\t15\n",
            "\"u\"\t13\n",
            "\"f\"\t11\n",
            "\"y\"\t9\n",
            "\"_\"\t9\n",
            "\"1\"\t9\n",
            "\"w\"\t8\n",
            "\"v\"\t8\n",
            "\":\"\t8\n",
            "\"9\"\t7\n",
            "\"7\"\t7\n",
            "\"-\"\t7\n",
            "\"`\"\t6\n",
            "\"8\"\t5\n",
            "\"3\"\t5\n",
            "\"2\"\t5\n",
            "\"*\"\t5\n",
            "\")\"\t5\n",
            "\"(\"\t5\n",
            "\"k\"\t4\n",
            "\"j\"\t4\n",
            "\"4\"\t4\n",
            "\"0\"\t4\n",
            "\"]\"\t3\n",
            "\"[\"\t3\n",
            "\"5\"\t3\n",
            "\"'\"\t3\n",
            "\"q\"\t2\n",
            "\";\"\t2\n",
            "\"6\"\t2\n",
            "\",\"\t2\n",
            "\"z\"\t1\n",
            "\"x\"\t1\n",
            "\"%\"\t1\n",
            "Removing temp directory /tmp/mr4.root.20200804.112758.440403...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyq7H_LzsFAA",
        "colab_type": "text"
      },
      "source": [
        "**California Housing Data Set** is California housing data from the 1990 US Census.  \n",
        "\n",
        "More information about the data set is available at: [this link.](https://developers.google.com/machine-learning/crash-course/california-housing-data-description)\n",
        "## Ex5\n",
        "+ Have a look at a few first lines of the data set `/content/sample_data/california_housing_train.csv`.\n",
        "+ Write and run a MapReduce code called `mr5.py` to find the maximum medianIncome.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUBZhYzWN0_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6391a257-1bc1-41f6-e4b1-be3a8d7258ac"
      },
      "source": [
        "%%writefile mr5.py\n",
        "from mrjob.job import MRJob\n",
        "\n",
        "class MaxMedIncome(MRJob):\n",
        "  def mapper(self, _, line):\n",
        "    income = line.split(',')\n",
        "    try:\n",
        "      yield 'income', float(income)\n",
        "    except:\n",
        "      pass\n",
        "      \n",
        "  def reducer(self, _, incomes):\n",
        "    yield 'Maximum medianIncome', (max(incomes))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  MaxMedIncome.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting mr5.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SS2AqJhAN0uw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "e5b3be9d-c792-49c4-ffaa-f2b12bf1090f"
      },
      "source": [
        "!python mr5.py < /content/sample_data/README.md"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory /tmp/mr5.root.20200804.112925.156045\n",
            "Running step 1 of 1...\n",
            "reading from STDIN\n",
            "job output is in /tmp/mr5.root.20200804.112925.156045/output\n",
            "Streaming final output from /tmp/mr5.root.20200804.112925.156045/output...\n",
            "Removing temp directory /tmp/mr5.root.20200804.112925.156045...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpV_XA4q6mLh",
        "colab_type": "text"
      },
      "source": [
        "## Combiner\n",
        "Imagine that you are counting the number of occurences for each word. If the mapper only output a pair of word-count where count is 1, then there is a lot of networ traffic between mapper nodes and reducer nodes.\n",
        "\n",
        "To reduce the amount of traffic, We use something called combiner. The idea is that we put a bit of reducer task to the mapper node. After the the map task, a mapper node process the result with the combiner before sending it to reducer nodes.\n",
        "\n",
        "Let's see an example of finding word frequencies:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rX4IeOAww2V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68783f01-4b5a-4f0d-e976-488b5cbd7132"
      },
      "source": [
        "%%writefile eg6.py\n",
        "\n",
        "from mrjob.job import MRJob\n",
        "import re\n",
        "\n",
        "WORD_RE = re.compile(r\"[\\w']+\")\n",
        "\n",
        "class WordFreq(MRJob):\n",
        "  def mapper(self, _, line):\n",
        "    for word in WORD_RE.findall(line):\n",
        "      yield word.lower(), 1\n",
        "  \n",
        "  def combiner(self, key, values):\n",
        "    yield key, sum(values)\n",
        "    \n",
        "  def reducer(self, key, values):\n",
        "    yield key, sum(values)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  WordFreq.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing eg6.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0J-SXIcyFx9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d93a2267-5bea-4a2b-8606-05421375e89a"
      },
      "source": [
        "!python eg6.py /content/sample_data/README.md "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory /tmp/eg6.root.20200804.112948.623929\n",
            "Running step 1 of 1...\n",
            "job output is in /tmp/eg6.root.20200804.112948.623929/output\n",
            "Streaming final output from /tmp/eg6.root.20200804.112948.623929/output...\n",
            "\"org\"\t2\n",
            "\"originally\"\t1\n",
            "\"our\"\t1\n",
            "\"prepared\"\t1\n",
            "\"quartet\"\t1\n",
            "\"sample\"\t2\n",
            "\"small\"\t1\n",
            "\"started\"\t1\n",
            "\"statistical\"\t1\n",
            "\"statistician\"\t1\n",
            "\"the\"\t3\n",
            "\"this\"\t1\n",
            "\"to\"\t1\n",
            "\"us\"\t1\n",
            "\"vega_datasets\"\t3\n",
            "\"viz\"\t1\n",
            "\"was\"\t2\n",
            "\"which\"\t1\n",
            "\"wiki\"\t2\n",
            "\"wikipedia\"\t2\n",
            "\"yann\"\t1\n",
            "\"you\"\t1\n",
            "\"from\"\t1\n",
            "\"get\"\t1\n",
            "\"github\"\t1\n",
            "\"google\"\t1\n",
            "\"housing\"\t2\n",
            "\"http\"\t1\n",
            "\"https\"\t4\n",
            "\"in\"\t2\n",
            "\"includes\"\t1\n",
            "\"information\"\t1\n",
            "\"is\"\t4\n",
            "\"it\"\t1\n",
            "\"j\"\t1\n",
            "\"json\"\t2\n",
            "\"jstor\"\t1\n",
            "\"learning\"\t1\n",
            "\"lecun\"\t1\n",
            "\"library\"\t1\n",
            "\"machine\"\t1\n",
            "\"mnist\"\t2\n",
            "\"mnist_\"\t1\n",
            "\"mnist_database\"\t1\n",
            "\"more\"\t1\n",
            "\"of\"\t2\n",
            "\"california\"\t2\n",
            "\"california_housing_data\"\t1\n",
            "\"census\"\t1\n",
            "\"com\"\t3\n",
            "\"contains\"\t1\n",
            "\"copy\"\t2\n",
            "\"course\"\t1\n",
            "\"crash\"\t1\n",
            "\"csv\"\t2\n",
            "\"data\"\t2\n",
            "\"database\"\t1\n",
            "\"datasets\"\t1\n",
            "\"described\"\t2\n",
            "\"description\"\t1\n",
            "\"developers\"\t1\n",
            "\"directory\"\t1\n",
            "\"en\"\t2\n",
            "\"exdb\"\t1\n",
            "\"f\"\t1\n",
            "\"few\"\t1\n",
            "\"'graphs\"\t1\n",
            "\"1\"\t1\n",
            "\"17\"\t1\n",
            "\"1973\"\t1\n",
            "\"1990\"\t1\n",
            "\"21\"\t1\n",
            "\"2682899\"\t1\n",
            "\"27\"\t1\n",
            "\"27s_quartet\"\t1\n",
            "\"4f67bdaad10f45e3549984e17e1b3088c731503d\"\t1\n",
            "\"_data\"\t1\n",
            "\"a\"\t3\n",
            "\"altair\"\t1\n",
            "\"american\"\t1\n",
            "\"analysis'\"\t1\n",
            "\"and\"\t1\n",
            "\"anscombe\"\t4\n",
            "\"anscombe's\"\t1\n",
            "\"at\"\t2\n",
            "\"available\"\t1\n",
            "\"blob\"\t1\n",
            "\"by\"\t1\n",
            "Removing temp directory /tmp/eg6.root.20200804.112948.623929...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRsynMxc9bkf",
        "colab_type": "text"
      },
      "source": [
        "Remark: The result is exactly the same as the case where we don't use a combiner. The difference is what happens behind the scene. The benefit of combiner would be seen when we process a huge amount of data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhVuittQ-LUG",
        "colab_type": "text"
      },
      "source": [
        "## Ex6\n",
        "\n",
        "Write and run a MapReduce code called `mr6.py` to find the mean and standard deviation of population in the data set `/content/sample_data/california_housing_train.csv`. Use one mapper, one combiner and one reducer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRFTS9qWPgJC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c3e022bc-7bc5-4b7e-f139-17635472da82"
      },
      "source": [
        "%%writefile mr6.py\n",
        "from mrjob.job import MRJob\n",
        "\n",
        "class MeanStdPop(MRJob):\n",
        "  def mapper(self, _, line):\n",
        "    population = line.split(',')[5]\n",
        "    try:\n",
        "      yield 'income', float(population)\n",
        "    except:\n",
        "      pass\n",
        "    \n",
        "  def combiner(self, _, populations):\n",
        "    n = 0\n",
        "    Sum = 0\n",
        "    Sum_squared = 0\n",
        "    for population in populations:\n",
        "      n += 1\n",
        "      Sum += population\n",
        "      Sum_squared += population**2\n",
        "    yield 'OneForAll', (n, Sum, Sum_squared)\n",
        "    \n",
        "  def reducer(self, _, n_Sum_Sum_squareds):\n",
        "    n = 0\n",
        "    Sum = 0\n",
        "    Sum_squared = 0\n",
        "    for n_Sum_Sum_squared in n_Sum_Sum_squareds:\n",
        "      n += n_Sum_Sum_squared[0]\n",
        "      Sum += n_Sum_Sum_squared[1]\n",
        "      Sum_squared += n_Sum_Sum_squared[2]\n",
        "    yield 'Mean and Std of population:', (Sum/n, (Sum_squared/n)**0.5)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  MeanStdPop.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing mr6.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8zxsL8aSG7J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "664a3bd6-eaef-4780-886b-7430d285d322"
      },
      "source": [
        "!python mr6.py /content/sample_data/california_housing_train.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory /tmp/mr6.root.20200804.114353.064060\n",
            "Running step 1 of 1...\n",
            "job output is in /tmp/mr6.root.20200804.114353.064060/output\n",
            "Streaming final output from /tmp/mr6.root.20200804.114353.064060/output...\n",
            "\"Mean and Std of population:\"\t[1429.5739411764705, 1833.3495480227698]\n",
            "Removing temp directory /tmp/mr6.root.20200804.114353.064060...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhCfaP-RQywk",
        "colab_type": "text"
      },
      "source": [
        "## EMR\n",
        "\n",
        "Amazon Elastic MapReduce is a web service that allows to process a vast amount of data. By using this cloud vervice, we don't need to invest in machines, maintain the system, pay the electricity bill to run the our jobs.\n",
        "\n",
        "1. To use EMR we need an [AWS](https://aws.amazon.com/) account and a credit card.\n",
        "\n",
        "2. Next we will create a key to use with mrjob. Sign in and go to [security credentials](https://console.aws.amazon.com/iam/home?#/security_credentials).\n",
        "\n",
        "3. Here you will see some warning: \"The account credentials provide unlimited access to your AWS resources.\" That's why you should keep your credentials safe or delete them after use, so that noone can have them and spend your money on the cloud. Here we choose \"Continue to Security Credentials\".\n",
        "\n",
        "4. Click the tab \"Access keys (access key ID and secret access key)\". Here you can create, inactivate/reactivate, or delete your keys.\n",
        "\n",
        "5. Choose \"Create New Access Key\". Then AWS states that the key has been created successfully. You can see it by clicking \"Show Access Key\". You can download it (a csv file that contains it) because AWS won't show you this key again. When you click \"close\" or the exit button, your key is ready to be used. \n",
        "\n",
        "The code below shows how to run mrjob with Elastic MapReduce:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGxgefzeFA8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set environment variable\n",
        "import os\n",
        "os.environ['AWS_ACCESS_KEY_ID'] = 'AKIAINQOIMOFV52AFX4A'\n",
        "os.environ['AWS_SECRET_ACCESS_KEY'] = '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'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWgJWVzgFEAq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "c81bf13d-e706-43b2-ba26-3c1a649ad72a"
      },
      "source": [
        "# run with emr by adding `-r emr`\n",
        "!python mr6.py -r emr /content/sample_data/california_housing_train.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for emr runner\n",
            "Traceback (most recent call last):\n",
            "  File \"mr6.py\", line 32, in <module>\n",
            "    MeanStdPop.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrjob/job.py\", line 616, in run\n",
            "    cls().execute()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrjob/job.py\", line 687, in execute\n",
            "    self.run_job()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrjob/job.py\", line 634, in run_job\n",
            "    with self.make_runner() as runner:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrjob/job.py\", line 713, in make_runner\n",
            "    return self._runner_class()(**self._runner_kwargs())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrjob/emr.py\", line 314, in __init__\n",
            "    self._fix_s3_tmp_and_log_uri_opts()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrjob/emr.py\", line 527, in _fix_s3_tmp_and_log_uri_opts\n",
            "    self._set_cloud_tmp_dir()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrjob/emr.py\", line 545, in _set_cloud_tmp_dir\n",
            "    for bucket_name in self.fs.s3.get_all_bucket_names():\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrjob/fs/s3.py\", line 332, in get_all_bucket_names\n",
            "    return [b['Name'] for b in c.list_buckets()['Buckets']]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrjob/retry.py\", line 108, in call_and_maybe_retry\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/botocore/client.py\", line 316, in _api_call\n",
            "    return self._make_api_call(operation_name, kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/botocore/client.py\", line 635, in _make_api_call\n",
            "    raise error_class(parsed_response, operation_name)\n",
            "botocore.exceptions.ClientError: An error occurred (NotSignedUp) when calling the ListBuckets operation: Your account is not signed up for the S3 service. You must sign up before you can use S3.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNmzWtuy4lkW",
        "colab_type": "text"
      },
      "source": [
        "As we can see, the program:\n",
        "+ Sets up a S3 directory (Amazon simple storage service).\n",
        "+ Uploads our data and our code to this directory.\n",
        "+ Creates a cluster and run the job\n",
        "+ Streams the final output (send it to us)\n",
        "+ Removes S3 directory, log files, and terminate the cluster.\n",
        "\n",
        "By default, for EMR, the region of cluster is 'us-west-2' Oregon. You can change the region using `--region 'us-east-1'`. You find the list of regions [here](https://docs.aws.amazon.com/general/latest/gr/rande.html). \n",
        "\n",
        "1. Go to your AWS console, choose the region of your cluster (by default Oregon), then go to EMR service. If it's the correct region, you will see your clusters there. \n",
        "\n",
        "2. If you click the black arrow on the left of your cluste tab (to expand), you can see more information, like the hardware or the steps of MapReduce job. \n",
        "\n",
        "3. Now, for more details you can click \"View cluster details\". Here we have several tabs from \"summary\" to \"Bootstrap actions\". \n",
        "\n",
        "4. In the tab \"Hardware\" you can the hardware of your cluster. By default, mrjob uses only one machine. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWEUtYVT2KFt",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Running several cores\n",
        "\n",
        "To increase the number of machines you can add `--num-core-instances 3`. Here 3 is the number of core (worker) instances. We have 1 master node (1 machine), so 4 machines in total.\n",
        "\n",
        "You should note that using 3 worker instances doesn't increase the speed 3 times. Therefore you will probably pay more. The processing time will probably decrease but less than 3 times (ideal case). That is because managing many machines takes some time.\n",
        "\n",
        "By default, the machine type for emr is `m5.xlarge` (more information: [machine types](https://aws.amazon.com/ec2/instance-types/), [pricing](https://aws.amazon.com/emr/pricing/))\n",
        "\n",
        "You can choose the type of machines by using `--instance-type 'm5.xlarge'`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwnrI2QLhOHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3 worker instances\n",
        "!python mr6.py -r emr --num-core-instances 3 /content/sample_data/california_housing_train.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQ6Ake5oHYU7",
        "colab_type": "text"
      },
      "source": [
        "## Ex7 (Debug EMR)\n",
        "\n",
        "Before running a MapReduce job on the cloud, we should debug it locally first. Sometimes even when the job runs well locally, we get some errors running it on the cloud, probably because of the difference between operating systems, packages, etc. \n",
        "\n",
        "Run the codes below, see EMR error messages and try to debug the code "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvfxPP1e-Rc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# example\n",
        "%%writefile eg7.py\n",
        "from mrjob.job import MRJob\n",
        "\n",
        "class MaxMedIncome(MRJob):\n",
        "  def mapper(self, _, line):\n",
        "    income = line.split(',')[7]\n",
        "    yield 'income', float(income)\n",
        "      \n",
        "  def reducer(self, _, incomes):\n",
        "    yield 'Maximum medianIncome', (max(incomes))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  MaxMedIncome.run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXy3dM7L3b7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run with emr\n",
        "!python eg7.py -r emr /content/sample_data/california_housing_train.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVrP9BgVJ-JX",
        "colab_type": "text"
      },
      "source": [
        "## Ex8\n",
        "\n",
        "Download (and extract) the [Book-Crossing Dataset](http://www2.informatik.uni-freiburg.de/~cziegler/BX/) collected by Cai-Nicolas Ziegler 2004. \n",
        "\n",
        "Write a MapReduce code `mr8.py` to find the top 10 popular books (top 10 ISBNs that have the largest number of rating). Run the code and save the result to `top10.txt`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJ8pqljScSv_",
        "colab_type": "text"
      },
      "source": [
        "## Ex9 (Ancillary data)\n",
        "\n",
        "The idea is that ancillary data is small enough. We use the ancillary data to extract some information which will be stored in an attribute of the MapReduce class.\n",
        "\n",
        "Complete the code of the mapper below to find the names of the top 10 popular books."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3QNh-fJQkdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Top 10 ISBN\n",
        "%%writefile mr9.py\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.step import MRStep\n",
        "\n",
        "class Top10book(MRJob):\n",
        "  \n",
        "  # define how to pass a file as argument\n",
        "  def configure_args(self):\n",
        "    super(Top10book, self).configure_args()\n",
        "    self.add_file_arg('--top10', help='Path to top10.txt')\n",
        "  \n",
        "  # define the method to process that file\n",
        "  # to create a new attribute called top10ISBN\n",
        "  def top10ISBN(self):\n",
        "    self.top10ISBN = {}\n",
        "    with open(\"top10.txt\", encoding='ascii', errors='ignore') as f:\n",
        "      for line in f:\n",
        "        count, ISBN = line.split()\n",
        "        self.top10ISBN[ISBN.strip('\"')] = count\n",
        "  \n",
        "  # the method will be called before mapper 1\n",
        "  def steps(self):\n",
        "    return [MRStep(mapper=self.mapper1, mapper_init=self.top10ISBN)]\n",
        "  \n",
        "  # we can then use the attribute top10ISBN in the mapper below\n",
        "  def mapper1(self, _, line):\n",
        "    ### \n",
        "    \n",
        "    # Some code here\n",
        "    \n",
        "    ###\n",
        "    \n",
        "if __name__ == '__main__':\n",
        "  Top10book.run()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiVsCz3vLV5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python mr9.py --top10 /content/top10.txt /content/BX-Books.csv "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpeFK3RBkjqh",
        "colab_type": "text"
      },
      "source": [
        "## Ex10 (extra)\n",
        "Find the names of the top 10 rated books (top 10 average rating)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyA4z5SkZvFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}